best <- rate$Cutoff[index]
best
fpr <- performance(ridge_prediction, 'fpr')@y.values[[1]]
cutoff <- performance(ridge_prediction, 'fpr')@x.values[[1]]
fnr <- performance(ridge_prediction, 'fnr')@y.values[[1]]
rate <- as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, FNR=fnr))
rate$distance <- sqrt((rate[,2])^2+(rate[,3])^2)
index <- which.min(rate$distance)
best <- rate$Cutoff[index]
best
rate
ridge_train_predict_prob
X_train_mat <- model.matrix(No_show~., data=train_dummy)[,-1]
X_test_mat <- model.matrix(No_show~., data=test_dummy)[,-1]
Y_train_num <- ifelse(train_dummy$No_show=='Yes',0,1)
Y_test_num <- ifelse(test_dummy$No_show=='Yes',0,1)
set.seed(786)
# tune ridge model
cv.ridge_initial <- cv.glmnet(X_train_mat, Y_train_num, alpha=0, lambda =
c(0.00001,0.0001,0.001,0.01,1), family='binomial',
foldid=folds)
# output optimal ridge lambda
cv.ridge_initial$lambda.min
set.seed(786)
# tune ridge model
cv.ridge <- cv.glmnet(X_train_mat, Y_train_num, alpha=0,
lambda=c(0.00005,0.00007,0.0001,0.0007,0.0005),
family='binomial', foldid=folds)
# output optimal ridge lambda
cv.ridge$lambda.min
# fit ridge model
ridge <- glmnet(X_train_mat, Y_train_num, family='binomial',lambda=
cv.ridge$lambda.min, alpha=0)
# coefficeints of the model
ridge$beta
ridge_train_predict_prob <- ridge %>% predict(newx=X_train_mat)
ridge_test_predict_prob <- ridge %>% predict(newx=X_test_mat)
ridge_train_predict_prob
?glmnet
ridge_train_predict_prob <- predict(ridge, newx=X_train_mat)
ridge_test_predict_prob <- ridge %>% predict(newx=X_test_mat)
ridge_test_predict_prob
ridge_train_predict_prob
ridge_train_predict_prob <- ridge %>% predict(newx=X_train_mat, type='response')
ridge_test_predict_prob <- ridge %>% predict(newx=X_test_mat, type='response')
ridge_train_predict_prob
ridge_prediction <- prediction(ridge_train_predict_prob, train_dummy$No_show)
ridge_perf <- performance(ridge_prediction, measure="tpr", x.measure="fpr")
plot(ridge_perf, col='red')
abline(0,1)
X_train_mat <- model.matrix(No_show~., data=train_dummy)[,-1]
X_test_mat <- model.matrix(No_show~., data=test_dummy)[,-1]
Y_train_num <- ifelse(train_dummy$No_show=='Yes',1,0)
Y_test_num <- ifelse(test_dummy$No_show=='Yes',1,0)
set.seed(786)
# tune ridge model
cv.ridge_initial <- cv.glmnet(X_train_mat, Y_train_num, alpha=0, lambda =
c(0.00001,0.0001,0.001,0.01,1), family='binomial',
foldid=folds)
# output optimal ridge lambda
cv.ridge_initial$lambda.min
set.seed(786)
# tune ridge model
cv.ridge <- cv.glmnet(X_train_mat, Y_train_num, alpha=0,
lambda=c(0.00005,0.00007,0.0001,0.0007,0.0005),
family='binomial', foldid=folds)
# output optimal ridge lambda
cv.ridge$lambda.min
# fit ridge model
ridge <- glmnet(X_train_mat, Y_train_num, family='binomial',lambda=
cv.ridge$lambda.min, alpha=0)
# coefficeints of the model
ridge$beta
ridge_train_predict_prob <- ridge %>% predict(newx=X_train_mat, type='response')
ridge_test_predict_prob <- ridge %>% predict(newx=X_test_mat, type='response')
ridge_prediction <- prediction(ridge_train_predict_prob, train_dummy$No_show)
ridge_perf <- performance(ridge_prediction, measure="tpr", x.measure="fpr")
plot(ridge_perf, col='red')
abline(0,1)
auc <- performance(ridge_prediction, 'auc')@y.values
auc
fpr <- performance(ridge_prediction, 'fpr')@y.values[[1]]
cutoff <- performance(ridge_prediction, 'fpr')@x.values[[1]]
fnr <- performance(ridge_prediction, 'fnr')@y.values[[1]]
rate <- as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, FNR=fnr))
rate$distance <- sqrt((rate[,2])^2+(rate[,3])^2)
index <- which.min(rate$distance)
best <- rate$Cutoff[index]
best
matplot(cutoff, cbind(fpr,fnr), xlab='Threshold', ylab='Error Rate', type='l',
col=2:3)
legend(0.3,1, legend=c('False Positive Rate','False Negative Rate'), col=c(2:3),
lty=c(1,2))
abline(v=best, col=4)
ridge_train_predict_val <- ifelse(ridge_train_predict_prob>=best, 'Yes','No')
ridge_train_error <- calc_error_rate(ridge_train_predict_val, train_dummy$No_show)
table(pred=ridge_train_predict_val, true=train_dummy$No_show)
ridge_test_predict_val <- ifelse(ridge_test_predict_prob>=best, 'Yes','No')
ridge_test_error <- calc_error_rate(ridge_test_predict_val, test_dummy$No_show)
records[2,1] <- ridge_train_error
records[2,2] <- ridge_test_error
table(pred=ridge_test_predict_val, true=test_dummy$No_show)
set.seed(233)
# tune lasso model
cv.lasso_initial <- cv.glmnet(X_train_mat, Y_train_num, alpha=1, lambda =
c(0.0000001,0.000001,0.00001,0.001,1),
family='binomial', foldid=folds)
# output optimal ridge lambda
cv.lasso_initial$lambda.min
set.seed(233)
# tune lasso model
cv.lasso <- cv.glmnet(X_train_mat, Y_train_num, alpha=1,
lambda=c(0.0000005,0.0000007,0.000001,0.000007,0.000005),
family='binomial', foldid=folds)
# output optimal lasso lambda
cv.lasso$lambda.min
# fit ridge model
lasso <- glmnet(X_train_mat, Y_train_num, family='binomial',lambda=
cv.lasso$lambda.min, alpha=1)
# coefficeints of the model
lasso$beta
lasso_train_predict_prob <- lasso %>% predict(newx=X_train_mat, type='response')
lasso_test_predict_prob <- lasso %>% predict(newx=X_test_mat, type='response')
lasso_prediction <- prediction(lasso_train_predict_prob, train_dummy$No_show)
lasso_perf <- performance(lasso_prediction, measure="tpr", x.measure="fpr")
plot(ridge_perf, col='red')
abline(0,1)
auc <- performance(lasso_prediction, 'auc')@y.values
auc
fpr <- performance(lasso_prediction, 'fpr')@y.values[[1]]
cutoff <- performance(lasso_prediction, 'fpr')@x.values[[1]]
fnr <- performance(lasso_prediction, 'fnr')@y.values[[1]]
rate <- as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, FNR=fnr))
rate$distance <- sqrt((rate[,2])^2+(rate[,3])^2)
index <- which.min(rate$distance)
best <- rate$Cutoff[index]
best
matplot(cutoff, cbind(fpr,fnr), xlab='Threshold', ylab='Error Rate', type='l',
col=2:3)
legend(0.3,1, legend=c('False Positive Rate','False Negative Rate'), col=c(2:3),
lty=c(1,2))
abline(v=best, col=4)
lasso_train_predict_val <- ifelse(lasso_train_predict_prob>=best, 'Yes','No')
lasso_train_error <- calc_error_rate(lasso_train_predict_val, train_dummy$No_show)
table(pred=lasso_train_predict_val, true=train_dummy$No_show)
lasso_test_predict_val <- ifelse(lasso_test_predict_prob>=best, 'Yes','No')
lasso_test_error <- calc_error_rate(lasso_test_predict_val, test_dummy$No_show)
records[3,1] <- lasso_train_error
records[3,2] <- lasso_test_error
table(pred=lasso_test_predict_val, true=test_dummy$No_show)
records
knitr::opts_chunk$set(echo = TRUE)
# global imports
library(tidyverse)
library(BAMMtools)
library(fastDummies)
library(ROCR)
library(glmnet)
# supress scientific notation
options(scipen=999)
raw_data <- read.csv('~/Documents/GitHub/DSC_Medical_ML/KaggleV2-May-2016.csv')
str(raw_data)
summary(raw_data)
sapply(raw_data, function(x) sum(is.na(x)))
clean_data <- raw_data
clean_data <- clean_data %>%
select(-c(PatientId, AppointmentID)) %>%
mutate(Scholarship=as.factor(ifelse(Scholarship==0,'No', 'Yes'))) %>%
mutate(Hipertension=as.factor(ifelse(Hipertension==0,'No', 'Yes'))) %>%
mutate(Diabetes=as.factor(ifelse(Diabetes==0,'No', 'Yes'))) %>%
mutate(Alcoholism=as.factor(ifelse(Alcoholism==0,'No', 'Yes'))) %>%
mutate(Handcap=as.factor(ifelse(Handcap==0,'No', 'Yes'))) %>%
mutate(SMS_received=as.factor(ifelse(SMS_received==0,'No', 'Yes')))
str(clean_data)
clean_data$ScheduledDay <-sapply(strsplit(as.character(clean_data$ScheduledDay),
'T'), "[",1)
clean_data$AppointmentDay<-sapply(strsplit(as.character(clean_data$AppointmentDay)
, 'T'), "[",1)
clean_data$ScheduledDay <- as.Date(clean_data$ScheduledDay)
clean_data$AppointmentDay <- as.Date(clean_data$AppointmentDay)
str(clean_data)
clean_data$ElapsedTime <- difftime(clean_data$AppointmentDay,
clean_data$ScheduledDay, units='days')
clean_data$ElapsedTime <- floor(clean_data$ElapsedTime)
clean_data$ElapsedTime <- as.numeric(clean_data$ElapsedTime)
clean_data$WeekDay <- as.factor(weekdays(clean_data$AppointmentDay))
clean_data <- clean_data %>% select(-c(ScheduledDay, AppointmentDay))
str(clean_data)
summary(clean_data)
clean_data[clean_data$ElapsedTime<0,]
clean_data <- clean_data %>% subset(clean_data$ElapsedTime>=0)
summary(clean_data)
clean_data[clean_data$Age==-1,]
clean_data <- clean_data %>% subset(clean_data$Age!=-1)
summary(clean_data)
d <- density(clean_data$ElapsedTime)
plot(d)
elapsed_cuts <- getJenksBreaks(clean_data$ElapsedTime, 12)
clean_data$ElapsedTime <- cut(clean_data$ElapsedTime, elapsed_cuts,
include.lowest=TRUE)
d <- density(clean_data$Age)
plot(d)
age_cuts <- getJenksBreaks(clean_data$Age, 9)
clean_data$Age <- cut(clean_data$Age, age_cuts, include.lowest=TRUE)
clean_data <- clean_data %>% select(-c(Neighbourhood))
clean_data <- clean_data %>% rename(No_show=No.show)
model_data <- clean_data
str(model_data)
summary(model_data)
dummy_data <- dummy_cols(model_data, remove_first_dummy=TRUE)
dummy_data <- dummy_data %>% select(-c(Gender, Age, Scholarship, Hipertension,
Diabetes, Alcoholism, Handcap,
SMS_received, ElapsedTime, WeekDay,
No_show_Yes))
str(dummy_data)
n <- nrow(model_data)
set.seed(123)
ind_train <- sample.int(n, 0.8*n)
train_full <- model_data[ind_train,]
test_full <- model_data[-ind_train,]
train_dummy <- dummy_data[ind_train,]
test_dummy <- dummy_data[-ind_train,]
X_train_mat <- model.matrix(No_show~., data=train_dummy)[,-1]
X_test_mat <- model.matrix(No_show~., data=test_dummy)[,-1]
Y_train_num <- ifelse(train_dummy$No_show=='Yes',1,0)
Y_test_num <- ifelse(test_dummy$No_show=='Yes',1,0)
# scale data
train_dummy_scaled <- train_dummy %>% mutate_if(is.numeric, scale)
test_dummy_scaled <- train_dummy %>% mutate_if(is.numeric, scale)
# break into predictors and response for KNN
X_train_dummy_scaled <- train_dummy_scaled %>% select(-c(No_show))
X_test_dummy_scaled <- test_dummy_scaled %>% select(-c(No_show))
Y_train <- train_dummy_scaled %>% select(c(No_show))
Y_test <- test_dummy_scaled %>% select(c(No_show))
set.seed(20)
nfold <- 10
folds <- sample(cut(1:nrow(train_dummy), breaks=nfold, labels=FALSE))
calc_error_rate = function(predicted.value, true.value){
return(mean(true.value!=predicted.value))
}
records = matrix(NA, nrow=9, ncol=2)
colnames(records) = c("train.error","test.error")
rownames(records) = c("Logistic Regression", "Ridge Regression",
"Lasso Regression", "K Nearest Neighbors",
"Decision Tree","Bagged Tree", "Random Forest",
"Adaboost", "Support Vector Machine")
logistic <- glm(No_show~., data=train_dummy, family=binomial)
summary(logistic)
logistic_train_predict_prob <- predict(logistic, train_dummy, type='response')
logistic_test_predict_prob <- predict(logistic, test_dummy, type='response')
logistic_prediction <- prediction(logistic_train_predict_prob,
train_dummy$No_show)
logistic_perf <- performance(logistic_prediction, measure="tpr", x.measure="fpr")
plot(logistic_perf, col='red')
abline(0,1)
auc <- performance(logistic_prediction, 'auc')@y.values
auc
fpr <- performance(logistic_prediction, 'fpr')@y.values[[1]]
cutoff <- performance(logistic_prediction, 'fpr')@x.values[[1]]
fnr <- performance(logistic_prediction, 'fnr')@y.values[[1]]
rate <- as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, FNR=fnr))
rate$distance <- sqrt((rate[,2])^2+(rate[,3])^2)
index <- which.min(rate$distance)
best <- rate$Cutoff[index]
best
matplot(cutoff, cbind(fpr,fnr), xlab='Threshold', ylab='Error Rate', type='l',
col=2:3)
legend(0.3,1, legend=c('False Positive Rate','False Negative Rate'), col=c(2:3),
lty=c(1,2))
abline(v=best, col=4)
logistic_train_predict_val <- ifelse(logistic_train_predict_prob>=best, 'Yes',
'No')
logistic_train_error <- calc_error_rate(logistic_train_predict_val,
train_dummy$No_show)
table(pred=logistic_train_predict_val, true=train_dummy$No_show)
logistic_test_predict_val <- ifelse(logistic_test_predict_prob>=best, 'Yes','No')
logistic_test_error <- calc_error_rate(logistic_test_predict_val,
test_dummy$No_show)
records[1,1] <- logistic_train_error
records[1,2] <- logistic_test_error
table(pred=logistic_test_predict_val, true=test_dummy$No_show)
set.seed(786)
# tune ridge model
cv.ridge_initial <- cv.glmnet(X_train_mat, Y_train_num, alpha=0, lambda =
c(0.00001,0.0001,0.001,0.01,1), family='binomial',
foldid=folds)
# output optimal ridge lambda
cv.ridge_initial$lambda.min
set.seed(786)
# tune ridge model
cv.ridge <- cv.glmnet(X_train_mat, Y_train_num, alpha=0,
lambda=c(0.00005,0.00007,0.0001,0.0007,0.0005),
family='binomial', foldid=folds)
# output optimal ridge lambda
cv.ridge$lambda.min
# fit ridge model
ridge <- glmnet(X_train_mat, Y_train_num, family='binomial',lambda=
cv.ridge$lambda.min, alpha=0)
# coefficeints of the model
ridge$beta
ridge_train_predict_prob <- ridge %>% predict(newx=X_train_mat, type='response')
ridge_test_predict_prob <- ridge %>% predict(newx=X_test_mat, type='response')
ridge_prediction <- prediction(ridge_train_predict_prob, train_dummy$No_show)
ridge_perf <- performance(ridge_prediction, measure="tpr", x.measure="fpr")
plot(ridge_perf, col='red')
abline(0,1)
auc <- performance(ridge_prediction, 'auc')@y.values
auc
fpr <- performance(ridge_prediction, 'fpr')@y.values[[1]]
cutoff <- performance(ridge_prediction, 'fpr')@x.values[[1]]
fnr <- performance(ridge_prediction, 'fnr')@y.values[[1]]
rate <- as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, FNR=fnr))
rate$distance <- sqrt((rate[,2])^2+(rate[,3])^2)
index <- which.min(rate$distance)
best <- rate$Cutoff[index]
best
matplot(cutoff, cbind(fpr,fnr), xlab='Threshold', ylab='Error Rate', type='l',
col=2:3)
legend(0.3,1, legend=c('False Positive Rate','False Negative Rate'), col=c(2:3),
lty=c(1,2))
abline(v=best, col=4)
ridge_train_predict_val <- ifelse(ridge_train_predict_prob>=best, 'Yes','No')
ridge_train_error <- calc_error_rate(ridge_train_predict_val, train_dummy$No_show)
table(pred=ridge_train_predict_val, true=train_dummy$No_show)
ridge_test_predict_val <- ifelse(ridge_test_predict_prob>=best, 'Yes','No')
ridge_test_error <- calc_error_rate(ridge_test_predict_val, test_dummy$No_show)
records[2,1] <- ridge_train_error
records[2,2] <- ridge_test_error
table(pred=ridge_test_predict_val, true=test_dummy$No_show)
set.seed(233)
# tune lasso model
cv.lasso_initial <- cv.glmnet(X_train_mat, Y_train_num, alpha=1, lambda =
c(0.0000001,0.000001,0.00001,0.001,1),
family='binomial', foldid=folds)
# output optimal ridge lambda
cv.lasso_initial$lambda.min
set.seed(233)
# tune lasso model
cv.lasso <- cv.glmnet(X_train_mat, Y_train_num, alpha=1,
lambda=c(0.0000005,0.0000007,0.000001,0.000007,0.000005),
family='binomial', foldid=folds)
# output optimal lasso lambda
cv.lasso$lambda.min
# fit ridge model
lasso <- glmnet(X_train_mat, Y_train_num, family='binomial',lambda=
cv.lasso$lambda.min, alpha=1)
# coefficeints of the model
lasso$beta
lasso_train_predict_prob <- lasso %>% predict(newx=X_train_mat, type='response')
lasso_test_predict_prob <- lasso %>% predict(newx=X_test_mat, type='response')
lasso_prediction <- prediction(lasso_train_predict_prob, train_dummy$No_show)
lasso_perf <- performance(lasso_prediction, measure="tpr", x.measure="fpr")
plot(ridge_perf, col='red')
abline(0,1)
auc <- performance(lasso_prediction, 'auc')@y.values
auc
fpr <- performance(lasso_prediction, 'fpr')@y.values[[1]]
cutoff <- performance(lasso_prediction, 'fpr')@x.values[[1]]
fnr <- performance(lasso_prediction, 'fnr')@y.values[[1]]
rate <- as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, FNR=fnr))
rate$distance <- sqrt((rate[,2])^2+(rate[,3])^2)
index <- which.min(rate$distance)
best <- rate$Cutoff[index]
best
matplot(cutoff, cbind(fpr,fnr), xlab='Threshold', ylab='Error Rate', type='l',
col=2:3)
legend(0.3,1, legend=c('False Positive Rate','False Negative Rate'), col=c(2:3),
lty=c(1,2))
abline(v=best, col=4)
lasso_train_predict_val <- ifelse(lasso_train_predict_prob>=best, 'Yes','No')
lasso_train_error <- calc_error_rate(lasso_train_predict_val, train_dummy$No_show)
table(pred=lasso_train_predict_val, true=train_dummy$No_show)
lasso_test_predict_val <- ifelse(lasso_test_predict_prob>=best, 'Yes','No')
lasso_test_error <- calc_error_rate(lasso_test_predict_val, test_dummy$No_show)
records[3,1] <- lasso_train_error
records[3,2] <- lasso_test_error
table(pred=lasso_test_predict_val, true=test_dummy$No_show)
# fit lasso model, cv.lasso$lambda.min
lasso <- glmnet(X_train_mat, Y_train_num, family='binomial',lambda=
0.01, alpha=1)
# coefficeints of the model
lasso$beta
lasso_train_predict_prob <- lasso %>% predict(newx=X_train_mat, type='response')
lasso_test_predict_prob <- lasso %>% predict(newx=X_test_mat, type='response')
lasso_prediction <- prediction(lasso_train_predict_prob, train_dummy$No_show)
lasso_perf <- performance(lasso_prediction, measure="tpr", x.measure="fpr")
plot(ridge_perf, col='red')
abline(0,1)
auc <- performance(lasso_prediction, 'auc')@y.values
auc
fpr <- performance(lasso_prediction, 'fpr')@y.values[[1]]
cutoff <- performance(lasso_prediction, 'fpr')@x.values[[1]]
fnr <- performance(lasso_prediction, 'fnr')@y.values[[1]]
fpr <- performance(lasso_prediction, 'fpr')@y.values[[1]]
cutoff <- performance(lasso_prediction, 'fpr')@x.values[[1]]
fnr <- performance(lasso_prediction, 'fnr')@y.values[[1]]
rate <- as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, FNR=fnr))
rate$distance <- sqrt((rate[,2])^2+(rate[,3])^2)
index <- which.min(rate$distance)
best <- rate$Cutoff[index]
best
matplot(cutoff, cbind(fpr,fnr), xlab='Threshold', ylab='Error Rate', type='l',
col=2:3)
legend(0.3,1, legend=c('False Positive Rate','False Negative Rate'), col=c(2:3),
lty=c(1,2))
abline(v=best, col=4)
lasso_train_predict_val <- ifelse(lasso_train_predict_prob>=best, 'Yes','No')
lasso_train_error <- calc_error_rate(lasso_train_predict_val, train_dummy$No_show)
table(pred=lasso_train_predict_val, true=train_dummy$No_show)
lasso_test_predict_val <- ifelse(lasso_test_predict_prob>=best, 'Yes','No')
lasso_test_error <- calc_error_rate(lasso_test_predict_val, test_dummy$No_show)
records[3,1] <- lasso_train_error
records[3,2] <- lasso_test_error
table(pred=lasso_test_predict_val, true=test_dummy$No_show)
records
do.chunk <- function(chunkid, folddef, Xdat, Ydat, k){
train = (folddef!=chunkid)
Xtr = Xdat[train,]
Ytr = Ydat[train]
Xvl = Xdat[!train,]
Yvl = Ydat[!train]
## get classifications for current training chunks
predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, k = k)
## get classifications for current test chunk
predYvl = knn(train = Xtr, test = Xvl, cl = Ytr, k = k)
data.frame(train.error = calc_error_rate(predYtr, Ytr),
val.error = calc_error_rate(predYvl, Yvl))
}
set.seed(1)
# possible number of neighbors
kvec <- c(1, seq(10,50,length.out=5))
CVs <- 1:10
error.folds <- NULL
for (k in kvec){
# apply do.chunk to each fold
tmp <- ldply(CVs, function(x) do.chunk(x, folds, X_train_dummy_scaled,
Y_train, k))
tmp$neighbors <- k
error.folds <- rbind(error.folds, tmp)
}
# global imports
library(tidyverse)
library(BAMMtools)
library(fastDummies)
library(ROCR)
library(glmnet)
library(plyr)
# supress scientific notation
options(scipen=999)
set.seed(1)
# possible number of neighbors
kvec <- c(1, seq(10,50,length.out=5))
CVs <- 1:10
error.folds <- NULL
for (k in kvec){
# apply do.chunk to each fold
tmp <- ldply(CVs, function(x) do.chunk(x, folds, X_train_dummy_scaled,
Y_train, k))
tmp$neighbors <- k
error.folds <- rbind(error.folds, tmp)
}
Y_train[1:4]
Y_train
Y_train[,1:4]
Y_train[1:4,]
do.chunk <- function(chunkid, folddef, Xdat, Ydat, k){
train = (folddef!=chunkid)
Xtr = Xdat[train,]
Ytr = Ydat[train,]
Xvl = Xdat[!train,]
Yvl = Ydat[!train,]
## get classifications for current training chunks
predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, k = k)
## get classifications for current test chunk
predYvl = knn(train = Xtr, test = Xvl, cl = Ytr, k = k)
data.frame(train.error = calc_error_rate(predYtr, Ytr),
val.error = calc_error_rate(predYvl, Yvl))
}
set.seed(1)
# possible number of neighbors
kvec <- c(1, seq(10,50,length.out=5))
CVs <- 1:10
error.folds <- NULL
for (k in kvec){
# apply do.chunk to each fold
tmp <- ldply(CVs, function(x) do.chunk(x, folds, X_train_dummy_scaled,
Y_train, k))
tmp$neighbors <- k
error.folds <- rbind(error.folds, tmp)
}
# global imports
library(tidyverse)
library(BAMMtools)
library(fastDummies)
library(ROCR)
library(glmnet)
library(plyr)
library(class)
# supress scientific notation
options(scipen=999)
set.seed(1)
# possible number of neighbors
kvec <- c(1, seq(10,50,length.out=5))
CVs <- 1:10
error.folds <- NULL
for (k in kvec){
# apply do.chunk to each fold
tmp <- ldply(CVs, function(x) do.chunk(x, folds, X_train_dummy_scaled,
Y_train, k))
tmp$neighbors <- k
error.folds <- rbind(error.folds, tmp)
}
